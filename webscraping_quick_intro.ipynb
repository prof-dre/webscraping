{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Very Quick Introduction to Web Scraping\n",
    "_Copyright 2020 Andre M. Maier_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import some necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use requests to load webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "req = requests.get(\"https://raw.githubusercontent.com/profqubit/webscraping/main/example1.html\", verify=True)\n",
    "print(req) # 200 -> ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build a BeautifulSoup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = req.content\n",
    "soup = BeautifulSoup(content)\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use BeautifulSoup to extract information\n",
    "\n",
    "BeautifulSoup maps the hierarchic structure of an HTML document into a tree of objects. You can navigate this tree by specifying HTML tags and by using specific attributes, e.g. .parent, .children, next_sibling, previous_sibling, and many more. Note that if you specify an HTML tag, it always refers to its first occurrance on the page.<br>\n",
    "The following examples will illustrate the principle.<br>\n",
    "For more information visit https://www.crummy.com/software/BeautifulSoup/bs4/doc/<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Example 1</title>\n",
      "<h1>The Black Cat</h1>\n",
      "---------------------------\n",
      "<head>\n",
      "<title>Example 1</title>\n",
      "</head>\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)\n",
    "print(soup.h1)\n",
    "print(\"---------------------------\")\n",
    "print(soup.title.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".contents allows you to extract all elements between an opening and closing tag as a list of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', <title>Example 1</title>, '\\n']\n",
      "['Example 1']\n"
     ]
    }
   ],
   "source": [
    "elements = soup.head.contents\n",
    "print(elements)\n",
    "title = elements[1]\n",
    "print(title.contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the .string generator to directly extract text between an opening and closing tag. Note that this only works with tags that actually contain a string!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1\n",
      "The word \"the\" occurs 12 times in the first paragraph.\n"
     ]
    }
   ],
   "source": [
    "print(soup.title.string)\n",
    "first_paragraph = soup.p.string\n",
    "print(\"The word \\\"the\\\" occurs\", first_paragraph.count(\"the\"), \"times in the first paragraph.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are only interested in the human readable text in a document or between tags, you can also use get_text(). In this case there will be no difference, as there is only human readable text in the first paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"the\" occurs 12 times in the first paragraph.\n"
     ]
    }
   ],
   "source": [
    "first_paragraph = soup.p.get_text()\n",
    "print(\"The word \\\"the\\\" occurs\", first_paragraph.count(\"the\"), \"times in the first paragraph.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to find and extract all occurrances of a specific HTML tag, you can use find_all()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 paragraphs on the web page.\n",
      "The text in the last paragraph is as follows: \n",
      " Of my own thoughts it is folly to speak. Swooning, I staggered to the opposite wall. For one instant the party upon the stairs remained motionless, through extremity of terror and of awe. In the next, a dozen stout arms were toiling at the wall. It fell bodily. The corpse, already greatly decayed and clotted with gore, stood erect before the eyes of the spectators. Upon its head, with red extended mouth and solitary eye of fire, sat the hideous beast whose craft had seduced me into murder, and whose informing voice had consigned me to the hangman. I had walled the monster up within the tomb! \n"
     ]
    }
   ],
   "source": [
    "list = soup.find_all('p')\n",
    "print(\"There are\", len(list), \"paragraphs on the web page.\")\n",
    "last_paragraph = list[len(list)-1]\n",
    "print(\"The text in the last paragraph is as follows: \\n\", last_paragraph.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find_all() is also able to match regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<title>Example 1</title>]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regex = re.compile('^t')\n",
    "tags_starting_with_t = soup.find_all(regex)\n",
    "print(tags_starting_with_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Write a Python program that loads Example #2 available at https://raw.githubusercontent.com/profqubit/webscraping/main/example2.html\n",
    "* Extract the following information:\n",
    " - A list that contains all food categories mentioned on the page\n",
    " - A list that contains all fruits, vegetables, nuts, and seeds mentioned on the page\n",
    " - A list that only contains all seeds mentioned on the page\n",
    " - The number of different fruits mentioned on the page\n",
    " - A list that containes all URLs referred to by the hyperlinks on the page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
